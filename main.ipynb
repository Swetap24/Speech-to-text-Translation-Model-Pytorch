{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-whU2LdLWPMb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.nn.utils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions.gumbel import Gumbel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MEswBGMPi1P_",
    "outputId": "2b29beb0-45a1-4e25-8b15-716f0c1a8c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading Sucessful.....\n"
     ]
    }
   ],
   "source": [
    "speech_train = np.load('train file path', allow_pickle=True, encoding='bytes')\n",
    "speech_valid = np.load('validation file path', allow_pickle=True, encoding='bytes')\n",
    "speech_test = np.load('test file path', allow_pickle=True, encoding='bytes')\n",
    "\n",
    "transcript_train = np.load('train transcripts file for testing', allow_pickle=True,encoding='bytes')\n",
    "transcript_valid = np.load('validation transcripts file for testing', allow_pickle=True,encoding='bytes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZczQfbdZL63"
   },
   "outputs": [],
   "source": [
    "letter_list = ['&','A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q',\\\n",
    "             'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '-', \"'\", '.', '_', '+', ' ','<sos>','<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vW7VaQyo9gRb"
   },
   "outputs": [],
   "source": [
    "a=transcript_train\n",
    "alls=[]\n",
    "for i, each in enumerate(a):\n",
    "    m=[]\n",
    "    for p, item in enumerate(a[i]):\n",
    "        for f, item2 in enumerate(a[i][p]):\n",
    "          if p==0 and f==0:\n",
    "              m.insert(0, '<sos>')\n",
    "              m.append(a[i][p].decode()[f])\n",
    "          elif p==len(a[i])-1 and f==len(a[i][p])-1:\n",
    "              m.append(a[i][p].decode()[f])\n",
    "              m.append('<eos>')\n",
    "          elif f==len(a[i][p])-1:\n",
    "              m.append(a[i][p].decode()[f])\n",
    "              m.append(\" \")\n",
    "          else:\n",
    "              m.append(a[i][p].decode()[f])\n",
    "    alls.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okO7pSZZSxNL"
   },
   "outputs": [],
   "source": [
    "a=transcript_valid\n",
    "allsv=[]\n",
    "for i, each in enumerate(a):\n",
    "    m=[]\n",
    "    for p, item in enumerate(a[i]):\n",
    "        for f, item2 in enumerate(a[i][p]):\n",
    "          if p==0 and f==0:\n",
    "              m.insert(0, '<sos>')\n",
    "              m.append(a[i][p].decode()[f])\n",
    "          elif p==len(a[i])-1 and f==len(a[i][p])-1:\n",
    "              m.append(a[i][p].decode()[f])\n",
    "              m.append('<eos>')\n",
    "          elif f==len(a[i][p])-1:\n",
    "              m.append(a[i][p].decode()[f])\n",
    "              m.append(\" \")\n",
    "          else:\n",
    "              m.append(a[i][p].decode()[f])\n",
    "    allsv.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJxyBV3baNGq"
   },
   "outputs": [],
   "source": [
    "def transform_letter_to_index(transcript, letter_list):\n",
    "    '''\n",
    "    :param transcript :(N, ) Transcripts are the text input\n",
    "    :param letter_list: Letter list defined above\n",
    "    :return letter_to_index_list: Returns a list for all the transcript sentence to index\n",
    "    '''\n",
    "    letter_to_index_list=[]   \n",
    "    for i, o in enumerate(transcript):\n",
    "      index_list=[] \n",
    "      for s, a in enumerate(transcript[i]):\n",
    "          check =  all(a in letter_list for item in transcript[i])\n",
    "          if check is True:\n",
    "              index_list.append(letter_list.index(a))\n",
    "      letter_to_index_list.append(index_list)\n",
    "    return letter_to_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "N0PAvYsrdaVk",
    "outputId": "a65e45e3-2a2f-468c-a789-d1b2b0adf0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data sucessfully.....\n",
      "[33, 20, 8, 5, 32, 6, 5, 13, 1, 12, 5, 32, 16, 18, 15, 4, 21, 3, 5, 19, 32, 1, 32, 12, 9, 20, 20, 5, 18, 32, 15, 6, 32, 20, 23, 15, 32, 20, 15, 32, 6, 15, 21, 18, 32, 25, 15, 21, 14, 7, 32, 9, 14, 32, 14, 15, 22, 5, 13, 2, 5, 18, 32, 1, 14, 4, 32, 4, 5, 3, 5, 13, 2, 5, 18, 34]\n"
     ]
    }
   ],
   "source": [
    "character_text_train = transform_letter_to_index(alls, letter_list)\n",
    "character_text_valid = transform_letter_to_index(allsv, letter_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SExEiY1egaV8"
   },
   "outputs": [],
   "source": [
    "class pBLSTM(nn.Module):\n",
    "\n",
    "  def __init__(self, input_dim, hidden_dim):\n",
    "      super(pBLSTM, self).__init__()\n",
    "      self.blstm = nn.LSTM(input_size=input_dim,hidden_size=hidden_dim,num_layers=1,bidirectional=True)\n",
    "  def forward(self,x):\n",
    "    return self.blstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qSqmfFHPpXyl"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, value_size=128,key_size=128):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.lstm = nn.LSTM(input_size=input_dim,hidden_size=hidden_dim,num_layers=1,bidirectional=True)\n",
    "    self.pBLSTM1= pBLSTM(2*hidden_dim, hidden_dim)\n",
    "    self.pBLSTM2= pBLSTM(2*hidden_dim, hidden_dim)\n",
    "    self.pBLSTM3= pBLSTM(2*hidden_dim, hidden_dim)\n",
    "    #Here you need to define the blocks of pBLSTMs\n",
    "    self.key_network = nn.Linear(hidden_dim*2, value_size)\n",
    "    self.value_network = nn.Linear(hidden_dim*2, key_size)\n",
    "  \n",
    "  def forward(self, x, lens):\n",
    "        rnn_inp=utils.rnn.pack_padded_sequence(x, lengths=lens, enforce_sorted=False)\n",
    "        outputs, _=self.lstm(rnn_inp)\n",
    "        linear_input, _=utils.rnn.pad_packed_sequence(outputs)\n",
    "        \n",
    "        for i in range(3):\n",
    "            if linear_input.shape[0]%2!=0:\n",
    "                linear_input = linear_input[:-1,:,:]\n",
    "            outputs = torch.transpose(linear_input, 0, 1)\n",
    "            outputs = outputs.contiguous().view(outputs.shape[0], outputs.shape[1]//2, 2, outputs.shape[2])\n",
    "            outputs = torch.mean(outputs, 2)\n",
    "            outputs = torch.transpose(outputs,0,1)\n",
    "            lens=lens//2\n",
    "            rnn_inp = utils.rnn.pack_padded_sequence(outputs, lengths=lens, enforce_sorted=False)\n",
    "            if i==0:\n",
    "                outputs, _=self.pBLSTM1(rnn_inp)\n",
    "            elif i==1:\n",
    "                outputs, _=self.pBLSTM2(rnn_inp)\n",
    "            else:\n",
    "                outputs, _=self.pBLSTM3(rnn_inp)\n",
    "            linear_input, _=utils.rnn.pad_packed_sequence(outputs)\n",
    "\n",
    "        # Generate key and value pairs\n",
    "        keys = self.key_network(linear_input)\n",
    "        value = self.value_network(linear_input)\n",
    "\n",
    "        return keys, value, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLNWuGepNFUm"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Attention, self).__init__()\n",
    "  def forward(self, query, key, value, lens):\n",
    "    '''\n",
    "    :param query :(N,context_size) Query is the output of LSTMCell from Decoder\n",
    "    :param key: (T,N,key_size) Key Projection from Encoder per time step\n",
    "    :param value: (T,N,value_size) Value Projection from Encoder per time step\n",
    "    :return output: Attended Context\n",
    "    :return attention_mask: Attention mask that can be plotted  \n",
    "    '''\n",
    "    key=torch.transpose(key, 0, 1)\n",
    "    attention=torch.bmm(key, query.unsqueeze(2)).squeeze(2)\n",
    "    mask=torch.arange(attention.size(1)).unsqueeze(0) >= lens.unsqueeze(1)\n",
    "    mask=mask.to(device)\n",
    "    attention.masked_fill_(mask, -1e9)\n",
    "    attention=nn.functional.softmax(attention, dim=1)\n",
    "    value=torch.transpose(value,0,1)\n",
    "    context=torch.bmm(attention.unsqueeze(1), value).squeeze(1)\n",
    "    return context, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7kuTqWYwY1o"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, vocab_size, hidden_dim, value_size=128, key_size=128,  isAttended=True):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=0)\n",
    "    \n",
    "    self.lstm1 = nn.LSTMCell(input_size=hidden_dim+value_size, hidden_size=hidden_dim)\n",
    "    self.lstm2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=key_size)\n",
    "    self.isAttended = isAttended\n",
    "    if(isAttended):\n",
    "      self.attention = Attention()\n",
    "    self.character_prob = nn.Linear(key_size+value_size,vocab_size)\n",
    "\n",
    "  def forward(self, key, values, lens, text=None, train=True):\n",
    "    '''\n",
    "    :param key :(T,N,key_size) Output of the Encoder Key projection layer\n",
    "    :param values: (T,N,value_size) Output of the Encoder Value projection layer\n",
    "    :param text: (N,text_len) Batch input of text with text_length\n",
    "    :param train: Train or eval mode\n",
    "    :return predictions: Returns the character perdiction probability \n",
    "    '''\n",
    "    batch_size=key.shape[1]\n",
    "    if(train):\n",
    "      text=torch.transpose(text,0,1)\n",
    "      max_len=text.shape[1]\n",
    "      embeddings=self.embedding(text)\n",
    "    else:\n",
    "      max_len = 250\n",
    "    \n",
    "    predictions = []\n",
    "    hidden_states = [None, None]\n",
    "    prediction = torch.zeros(batch_size,1).to(device)\n",
    "    context=values[0,:,:]\n",
    "    for i in range(max_len):\n",
    "      if(train):\n",
    "          if np.random.random_sample() > 0.6:\n",
    "              prediction = Gumbel(prediction.to('cpu'), torch.tensor([0.4])).sample().to(device)\n",
    "              char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "          else:\n",
    "              char_embed = embeddings[:,i,:]\n",
    "      else:\n",
    "          char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "     \n",
    "      inp = torch.cat([char_embed,context], dim=1)\n",
    "      hidden_states[0] = self.lstm1(inp,hidden_states[0])\n",
    "      \n",
    "      inp_2 = hidden_states[0][0]\n",
    "      hidden_states[1] = self.lstm2(inp_2,hidden_states[1])\n",
    "\n",
    "      output = hidden_states[1][0]\n",
    "      context, attention=self.attention(output, key, values, lens)\n",
    "      prediction = self.character_prob(torch.cat([output, context], dim=1))\n",
    "      predictions.append(prediction.unsqueeze(1))\n",
    "\n",
    "    return torch.cat(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bh5YsrFkweme"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "  def __init__(self,input_dim,vocab_size,hidden_dim,value_size=128, key_size=128,isAttended=True):\n",
    "    super(Seq2Seq,self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(input_dim, hidden_dim)\n",
    "    self.decoder = Decoder(vocab_size, hidden_dim, isAttended=True)\n",
    "  def forward(self,speech_input, speech_len, text_input=None,train=True):\n",
    "    key, value, length = self.encoder(speech_input, speech_len)\n",
    "    if(train):\n",
    "      predictions = self.decoder(key, value, length, text_input, train=True)\n",
    "    else:\n",
    "      predictions = self.decoder(key, value, length, text=None, train=False)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATSnaZJxwg-B"
   },
   "outputs": [],
   "source": [
    "class Speech2Text_Dataset(Dataset):\n",
    "  def __init__(self, speech, text=None, train=True):\n",
    "    self.speech = speech\n",
    "    self.train = train\n",
    "    if(text is not None):\n",
    "      self.text = text\n",
    "  def __len__(self):\n",
    "    return self.speech.shape[0]\n",
    "  def __getitem__(self, index):\n",
    "    if(self.train):\n",
    "      text = self.text[index]\n",
    "      return torch.tensor(self.speech[index].astype(np.float32)), torch.tensor(text[:-1]), torch.tensor(text[1:])\n",
    "    else:\n",
    "      return torch.tensor(self.speech[index].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJjxrhXZIx3A"
   },
   "outputs": [],
   "source": [
    "def collate_train(batch_data):\n",
    "    inputs, text_input, Labels = zip(*batch_data)\n",
    "    #Input\n",
    "    lens=[len(seq) for seq in inputs]\n",
    "    inputs=[inputs[i] for i in range(len(lens))]\n",
    "    Len1=torch.LongTensor([len(inp) for inp in inputs])\n",
    "    inputs=utils.rnn.pad_sequence(inputs)\n",
    "    #Pred\n",
    "    lens2=[len(seq) for seq in text_input]\n",
    "    text_input=[text_input[i] for i in range(len(lens2))]\n",
    "    Len2=torch.LongTensor([len(inp) for inp in text_input])\n",
    "    text_input = utils.rnn.pad_sequence(text_input)\n",
    "    #True\n",
    "    lens3=[len(seq) for seq in Labels]   \n",
    "    Labels=[Labels[i] for i in range(len(lens3))]   \n",
    "    Len3=torch.LongTensor([len(inp) for inp in Labels])\n",
    "    Labels = utils.rnn.pad_sequence(Labels)\n",
    "    \n",
    "    return inputs, text_input, Labels, Len1, Len2, Len3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-o9vfRlZPrA"
   },
   "outputs": [],
   "source": [
    "def collate_test(batch_data):\n",
    "    x=batch_data\n",
    "    lens=[len(seq) for seq in x]\n",
    "    x1=sorted(range(len(lens)), key=lens.__getitem__, reverse=True)\n",
    "    x=[x[i] for i in x1]\n",
    "    len1=torch.LongTensor([len(inp) for inp in x])\n",
    "    x=utils.rnn.pad_sequence(x)\n",
    "    return x, len1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DXPb8jZwmAQ"
   },
   "outputs": [],
   "source": [
    "Speech2Text_train_Dataset = Speech2Text_Dataset(speech_train, character_text_train)\n",
    "Speech2Text_val_Dataset = Speech2Text_Dataset(speech_valid, character_text_valid)\n",
    "Speech2Text_test_Dataset = Speech2Text_Dataset(speech_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_PiKQ-BwoZS"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Speech2Text_train_Dataset, batch_size=64, shuffle=True, collate_fn=collate_train)\n",
    "val_loader = DataLoader(Speech2Text_val_Dataset, batch_size=1, shuffle=False, collate_fn=collate_train)\n",
    "test_loader = DataLoader(Speech2Text_test_Dataset, batch_size=1, shuffle=False, collate_fn=collate_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MHi-gBlrYZi"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "T3j1Ued4wqp2",
    "outputId": "2cd2f36e-de28-42ef-964b-7fe57e3e65c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(input_dim=40,vocab_size=len(letter_list),hidden_dim=512,value_size=128, key_size=128)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam (model.parameters(), lr=0.00025)\n",
    "criterion = nn.CrossEntropyLoss(reduce=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMi7kND3wufr"
   },
   "outputs": [],
   "source": [
    "def train(model,train_loader, num_epochs, criterion, optimizer):\n",
    "  for epochs in range(num_epochs):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for batch_num,(speech_input, text_input, Labels, speech_len, text_len, Labels_len) in enumerate(train_loader):\n",
    "      with torch.autograd.set_detect_anomaly(True):\n",
    "          speech_input=speech_input.to(device)\n",
    "          text_input=text_input.to(device)\n",
    "          Labels=Labels.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          pred = model(speech_input, speech_len, text_input)\n",
    "          mask = torch.zeros(Labels.T.size()).to(device)\n",
    "          pred = pred.contiguous().view(-1, pred.size(-1))\n",
    "          Labels = torch.transpose(Labels,0,1).contiguous().view(-1)\n",
    "\n",
    "          for idx, length in enumerate(Labels_len):\n",
    "              mask[:length,idx] = 1\n",
    "          \n",
    "          mask = mask.contiguous().view(-1).to(device)\n",
    "          loss = criterion(pred, Labels)\n",
    "          masked_loss = torch.sum(loss*mask)\n",
    "          masked_loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "          optimizer.step()\n",
    "          current_loss = float(masked_loss.item())/int(torch.sum(mask).item())\n",
    "\n",
    "          if  batch_num % 25 == 1:\n",
    "            print('Epoch: ',epochs, 'Train_loss: ', current_loss)\n",
    "          torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLZ2EW2EyGOm"
   },
   "outputs": [],
   "source": [
    "train(model, train_loader, 5, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbHDiU6NtpFq"
   },
   "outputs": [],
   "source": [
    "model = torch.save(\"save path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_T7GS83a-CbC"
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"load path\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Kaggle4_final_(1) (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
